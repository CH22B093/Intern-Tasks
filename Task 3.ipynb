{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d11af5c-ad4c-47dc-818c-6a2372194a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"   \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"    \n",
    "import xml.etree.ElementTree as ET\n",
    "import streamlit as st\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d0059-91a7-4b2a-b4d7-cc4f0d7f16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_medquad_data_recursive(root_folder: str):\n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    questions, answers = [], []\n",
    "    file_count = 0\n",
    "    for current_dir, subdirs, files in os.walk(root_folder):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith(\".xml\"):\n",
    "                file_count += 1\n",
    "                filepath = os.path.join(current_dir, filename)\n",
    "                logger.info(f\"Parsing file #{file_count}: {filepath}\")\n",
    "                try:\n",
    "                    tree = ET.parse(filepath)\n",
    "                    root = tree.getroot()\n",
    "                    for qa_pair in root.findall(\".//QAPair\"):\n",
    "                        q_elem = qa_pair.find(\"Question\")\n",
    "                        a_elem = qa_pair.find(\"Answer\")\n",
    "                        if q_elem is not None and a_elem is not None:\n",
    "                            q_text = q_elem.text\n",
    "                            a_text = a_elem.text\n",
    "                            if q_text and a_text:\n",
    "                                questions.append(q_text.strip())\n",
    "                                answers.append(a_text.strip())\n",
    "                except ET.ParseError:\n",
    "                    pass\n",
    "    logger.info(f\"Total XML files found: {file_count}\")\n",
    "    logger.info(f\"Total questions: {len(questions)}; Total answers: {len(answers)}\")\n",
    "    return questions, answers\n",
    "\n",
    "def load_spacy_model(model_name: str = \"en_core_web_sm\"):\n",
    "    try:\n",
    "        return spacy.load(model_name)\n",
    "    except OSError:\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    st.title(\"Medical Q&A Chatbot\")\n",
    "    medquad_root_folder = r\"C:\\Users\\Roopesh P\\OneDrive\\Pictures\\Documents\\Task 3\\MedQuAD-master\\MedQuAD-master\"  #add your own root folder\n",
    "    questions, answers = load_medquad_data_recursive(medquad_root_folder)\n",
    "    nlp = load_spacy_model(\"en_core_web_sm\")\n",
    "    embedding_model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "    import torch\n",
    "    if answers:\n",
    "        batch_size = 256  \n",
    "        all_embeddings = []\n",
    "        for start_idx in range(0, len(answers), batch_size):\n",
    "            batch = answers[start_idx:start_idx+batch_size]\n",
    "            emb = embedding_model.encode(batch, convert_to_tensor=True)\n",
    "            all_embeddings.append(emb)\n",
    "        answer_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    else:\n",
    "        answer_embeddings = None\n",
    "    user_question = st.text_input(\"Ask a medical question:\")\n",
    "    if user_question:\n",
    "        if nlp:\n",
    "            doc = nlp(user_question)\n",
    "            entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "            if entities:\n",
    "                st.write(\"Recognized Entities:\")\n",
    "                for text, label in entities:\n",
    "                    st.write(f\"â€¢ {text} ({label})\")\n",
    "        if embedding_model and answer_embeddings is not None:\n",
    "            query_embedding = embedding_model.encode(user_question, convert_to_tensor=True)\n",
    "            cos_scores = util.pytorch_cos_sim(query_embedding, answer_embeddings)[0]\n",
    "            best_idx = int(cos_scores.argmax())\n",
    "            best_answer = answers[best_idx]\n",
    "            st.write(\"Question:\")\n",
    "            st.write(user_question)\n",
    "            st.write(\"Answer:\")\n",
    "            st.write(best_answer)\n",
    "        else:\n",
    "            st.write(\"No embeddings found; please check if the dataset is loaded correctly.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
